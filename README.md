# Data Analyst Agent

An **enterprise-grade AI-powered data analysis platform** built with **FastAPI, LangChain, and Google Generative AI (Gemini)**. Designed for **TDS Project 2**, it enables automated insights, visualization, and reporting with an intuitive web interface.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸš€ Key Features

- ğŸ¤– **AI-Powered Analysis** â€“ Uses Google Gemini API for natural language data interpretation  
- ğŸ“Š **Advanced Visualizations** â€“ Publication-ready charts via Matplotlib & Seaborn  
- ğŸŒ **Web Scraping** â€“ Fetches and analyzes real-time data  
- ğŸ“ˆ **Multi-Format Support** â€“ Works with CSV, Excel, JSON, Parquet & TXT  
- âš¡ **Batch Processing** â€“ Handle multiple queries in one go  
- ğŸ”’ **Secure by Design** â€“ Local data processing & secure API key management  

---

## ğŸ“¦ Quick Start

### Prerequisites
- Python **3.8+**
- Google Cloud account (for Gemini API)
- Git

### Installation

```bash
# Clone repository
git clone https://github.com/Simhadri123/data_analyst.git
cd data_analyst/Data_Analyst/TDS-project-2-Sameer

# Create virtual environment
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.template .env
# Edit .env with your API keys

# Start server
uvicorn app:app --reload --host 0.0.0.0 --port 8000
````

Visit: [http://localhost:8000](http://localhost:8000) ğŸ‰

---

## ğŸ’¡ Usage

### Example Queries (`questions.txt`)

```
What is the correlation between sales and marketing spend?
Show the top 5 products by revenue.
Plot a time series of monthly growth.
```

Supports:

* ğŸ“ˆ Statistical Analysis â†’ regression, correlations
* ğŸ”® Forecasting â†’ predict sales, growth trends
* ğŸ›  Data Quality â†’ detect outliers, anomalies

---

## ğŸ›  Architecture

### Backend

| Component       | Technology                    |
| --------------- | ----------------------------- |
| API Framework   | FastAPI                       |
| AI Engine       | Google Generative AI (Gemini) |
| Orchestration   | LangChain                     |
| Data Processing | Pandas, NumPy                 |
| Visualization   | Matplotlib, Seaborn           |
| Graph Analysis  | NetworkX                      |

### Frontend

* HTML5, CSS, JavaScript
* Bootstrap components
* Interactive real-time updates

---

## ğŸ“Š Supported File Formats

| Format  | Extensions      |
| ------- | --------------- |
| CSV     | `.csv`          |
| Excel   | `.xlsx`, `.xls` |
| JSON    | `.json`         |
| Parquet | `.parquet`      |
| Text    | `.txt`          |

---

## ğŸ”§ Configuration

### Environment Variables

```env
# Google Gemini API Keys (supports multiple keys for load balancing)
gemini_api_1=your_primary_key
gemini_api_2=your_secondary_key
# ... up to gemini_api_10

# App Settings
LLM_TIMEOUT_SECONDS=240
PORT=8000
```

Security:

* âœ… Data stays local
* âœ… API keys stored securely
* âœ… Configurable CORS for production

---

## ğŸš€ Deployment

### Local

```bash
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

### Docker

```bash
docker build -t tds-data-analyst .
docker run -p 8000:8000 --env-file .env tds-data-analyst
```

### Production

See [DEPLOYMENT\_GUIDE.md](DEPLOYMENT_GUIDE.md)

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py               # FastAPI app
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ Dockerfile            # Container setup
â”œâ”€â”€ entrypoint.sh         # Docker entry script
â”œâ”€â”€ index.html            # Frontend
â”œâ”€â”€ .env.template         # Env template
â””â”€â”€ DEPLOYMENT_GUIDE.md   # Deployment instructions
```

---

## ğŸ“ˆ Performance & Scalability

* âš¡ Async processing with FastAPI
* ğŸ”‘ API key load balancing
* ğŸ—„ï¸ Caching for repeated queries
* ğŸ§  Optimized memory use for large datasets

---

## ğŸ” Troubleshooting

* **API Key Errors** â†’ check `.env`
* **Memory Issues** â†’ reduce dataset or increase system resources
* **Port in Use** â†’ change `PORT` in `.env` or Docker run
* **Timeouts** â†’ raise `LLM_TIMEOUT_SECONDS`

Logs:

```bash
docker logs <container_id>
```

Health check:

```bash
curl http://localhost:8000/summary
```

---

## ğŸ¤ Contributing

1. Fork repo
2. Create a feature branch
3. Commit changes + add tests
4. Open a PR

---

## ğŸ“œ License

MIT License â€“ see [LICENSE](LICENSE)

---



Do you want me to also **add shields.io badges** for things like Docker, Pandas, NumPy, Seaborn, etc., to make it look even more polished?
```
